{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>å–®ä½ä»£è™Ÿ</th>\n",
       "      <th>å–®ä½åç¨±</th>\n",
       "      <th>é …ç›®</th>\n",
       "      <th>å¹´ä»½</th>\n",
       "      <th>æœˆä»½</th>\n",
       "      <th>è²»ç”¨</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A001</td>\n",
       "      <td>å·¥åœ°ä¸€è™Ÿ</td>\n",
       "      <td>æ°´è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>4845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A001</td>\n",
       "      <td>å·¥åœ°ä¸€è™Ÿ</td>\n",
       "      <td>æ°´è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>2</td>\n",
       "      <td>5064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A001</td>\n",
       "      <td>å·¥åœ°ä¸€è™Ÿ</td>\n",
       "      <td>æ°´è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>3</td>\n",
       "      <td>5397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A001</td>\n",
       "      <td>å·¥åœ°ä¸€è™Ÿ</td>\n",
       "      <td>æ°´è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>4839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A001</td>\n",
       "      <td>å·¥åœ°ä¸€è™Ÿ</td>\n",
       "      <td>æ°´è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>5</td>\n",
       "      <td>4591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>A005</td>\n",
       "      <td>å·¥åœ°äº”è™Ÿ</td>\n",
       "      <td>ç¶²è·¯è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>8</td>\n",
       "      <td>3112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>A005</td>\n",
       "      <td>å·¥åœ°äº”è™Ÿ</td>\n",
       "      <td>ç¶²è·¯è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>9</td>\n",
       "      <td>3124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>A005</td>\n",
       "      <td>å·¥åœ°äº”è™Ÿ</td>\n",
       "      <td>ç¶²è·¯è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>10</td>\n",
       "      <td>3451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>A005</td>\n",
       "      <td>å·¥åœ°äº”è™Ÿ</td>\n",
       "      <td>ç¶²è·¯è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>11</td>\n",
       "      <td>2580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>A005</td>\n",
       "      <td>å·¥åœ°äº”è™Ÿ</td>\n",
       "      <td>ç¶²è·¯è²»</td>\n",
       "      <td>2024</td>\n",
       "      <td>12</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     å–®ä½ä»£è™Ÿ  å–®ä½åç¨±   é …ç›®    å¹´ä»½  æœˆä»½    è²»ç”¨\n",
       "0    A001  å·¥åœ°ä¸€è™Ÿ   æ°´è²»  2024   1  4845\n",
       "1    A001  å·¥åœ°ä¸€è™Ÿ   æ°´è²»  2024   2  5064\n",
       "2    A001  å·¥åœ°ä¸€è™Ÿ   æ°´è²»  2024   3  5397\n",
       "3    A001  å·¥åœ°ä¸€è™Ÿ   æ°´è²»  2024   4  4839\n",
       "4    A001  å·¥åœ°ä¸€è™Ÿ   æ°´è²»  2024   5  4591\n",
       "..    ...   ...  ...   ...  ..   ...\n",
       "175  A005  å·¥åœ°äº”è™Ÿ  ç¶²è·¯è²»  2024   8  3112\n",
       "176  A005  å·¥åœ°äº”è™Ÿ  ç¶²è·¯è²»  2024   9  3124\n",
       "177  A005  å·¥åœ°äº”è™Ÿ  ç¶²è·¯è²»  2024  10  3451\n",
       "178  A005  å·¥åœ°äº”è™Ÿ  ç¶²è·¯è²»  2024  11  2580\n",
       "179  A005  å·¥åœ°äº”è™Ÿ  ç¶²è·¯è²»  2024  12  3198\n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#åŒ¯å…¥æ•¸æ“š\n",
    "\n",
    "file_path = \".\\\\raw_data.xlsx\"\n",
    "# è®€å–è³‡æ–™ï¼Œè·³éå‰é¢å¤šé¤˜çš„æ¨™é¡Œåˆ—ï¼Œä¸¦è¨­ç½®æ­£ç¢ºçš„æ¨™é¡Œè¡Œ\n",
    "df = pd.read_excel(file_path)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA001ï¼Œé …ç›®ï¼šæ°´è²»\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA001ï¼Œé …ç›®ï¼šé›»è²»\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA001ï¼Œé …ç›®ï¼šç¶²è·¯è²»\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA002ï¼Œé …ç›®ï¼šæ°´è²»\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA002ï¼Œé …ç›®ï¼šé›»è²»\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA002ï¼Œé …ç›®ï¼šç¶²è·¯è²»\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA003ï¼Œé …ç›®ï¼šæ°´è²»\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA003ï¼Œé …ç›®ï¼šé›»è²»\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA003ï¼Œé …ç›®ï¼šç¶²è·¯è²»\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA004ï¼Œé …ç›®ï¼šæ°´è²»\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA004ï¼Œé …ç›®ï¼šé›»è²»\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA004ï¼Œé …ç›®ï¼šç¶²è·¯è²»\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA005ï¼Œé …ç›®ï¼šæ°´è²»\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA005ï¼Œé …ç›®ï¼šé›»è²»\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "æ­£åœ¨è™•ç†å–®ä½ï¼šA005ï¼Œé …ç›®ï¼šç¶²è·¯è²»\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "âœ… å®Œæ•´è²»ç”¨ç•°å¸¸åµæ¸¬å ±å‘Šå·²åŒ¯å‡ºï¼ï¼ˆå«æ­£å¸¸èˆ‡ç•°å¸¸æ•¸æ“šï¼‰\n"
     ]
    }
   ],
   "source": [
    "#æ ¹æ“šå·¥åœ°è²»ç”¨æ•¸æ“šç‰¹æ€§ï¼Œå„ªåŒ–äº† Autoencoder çµæ§‹èˆ‡è¨“ç·´åƒæ•¸ï¼Œæ¡ç”¨è¼ƒæ·ºå±¤ç¥ç¶“ç¶²è·¯é¿å…éæ“¬åˆï¼Œä¸¦ä¾æ“šä¸åŒè²»ç”¨é¡å‹å‹•æ…‹èª¿æ•´ç•°å¸¸åˆ¤å®šé–¾å€¼ï¼Œæå‡åµæ¸¬æº–ç¢ºç‡èˆ‡å¯¦ç”¨æ€§ã€‚\n",
    "\n",
    "# åˆå§‹åŒ–çµæœå„²å­˜\n",
    "results = []\n",
    "\n",
    "# ç²å–æ‰€æœ‰å–®ä½èˆ‡é …ç›®é¡å‹çš„çµ„åˆ\n",
    "unit_list = df['å–®ä½ä»£è™Ÿ'].unique()\n",
    "expense_types = df['é …ç›®'].unique()\n",
    "\n",
    "for unit in unit_list:\n",
    "    for expense in expense_types:\n",
    "        print(f\"æ­£åœ¨è™•ç†å–®ä½ï¼š{unit}ï¼Œé …ç›®ï¼š{expense}\")\n",
    "\n",
    "        unit_data = df[(df['å–®ä½ä»£è™Ÿ'] == unit) & (df['é …ç›®'] == expense)].copy()\n",
    "\n",
    "        if unit_data.shape[0] < 10:\n",
    "            print(f\"âš ï¸ å–®ä½ {unit} çš„ {expense} æ•¸æ“šä¸è¶³ï¼Œå·²è·³é\")\n",
    "            continue\n",
    "\n",
    "        #  æ¨™æº–åŒ–è²»ç”¨\n",
    "        scaler = StandardScaler()\n",
    "        unit_scaled = scaler.fit_transform(unit_data[['è²»ç”¨']])\n",
    "\n",
    "        #  å®šç¾©è¼¸å…¥ç¶­åº¦\n",
    "        input_dim = unit_scaled.shape[1]\n",
    "\n",
    "        #  å»ºæ§‹ Autoencoder æ¨¡å‹\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        encoded = Dense(4, activation=\"relu\")(input_layer)\n",
    "        encoded = Dense(2, activation=\"relu\")(encoded)\n",
    "        decoded = Dense(4, activation=\"relu\")(encoded)\n",
    "        decoded = Dense(input_dim, activation=\"linear\")(decoded)\n",
    "\n",
    "        autoencoder = Model(input_layer, decoded)\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        autoencoder.fit(unit_scaled, unit_scaled, epochs=100, batch_size=4, validation_split=0.2, verbose=0)\n",
    "\n",
    "        #  é æ¸¬é‡å»ºèª¤å·®\n",
    "        reconstructed = autoencoder.predict(unit_scaled)\n",
    "        mse = np.mean(np.power(unit_scaled - reconstructed, 2), axis=1)\n",
    "\n",
    "        #  è¨­å®šç•°å¸¸é–¾å€¼\n",
    "        mse_threshold = np.percentile(mse, 95)\n",
    "        unit_data['MSE'] = mse\n",
    "        unit_data['ç•°å¸¸é–¾å€¼'] = mse_threshold\n",
    "        unit_data['anomaly'] = mse > mse_threshold\n",
    "\n",
    "        #  è¨ˆç®—å¹³å‡è²»ç”¨èˆ‡è¶…å‡ºç™¾åˆ†æ¯”\n",
    "        avg_fee = unit_data['è²»ç”¨'].mean()\n",
    "        unit_data['å¹³å‡è²»ç”¨'] = avg_fee\n",
    "\n",
    "        unit_data['è¶…å‡ºå¹³å‡ç™¾åˆ†æ¯”'] = np.where(\n",
    "            avg_fee == 0,\n",
    "            0,\n",
    "            ((unit_data['è²»ç”¨'] - avg_fee) / avg_fee) * 100\n",
    "        )\n",
    "\n",
    "        results.append(unit_data)\n",
    "\n",
    "# åˆä½µæ‰€æœ‰çµæœ\n",
    "df_result = pd.concat(results)\n",
    "\n",
    "# ğŸ”¹ åœ¨é€™è£¡æ’å…¥ï¼šåŒ¯å‡ºå®Œæ•´æ•¸æ“šå ±å‘Š\n",
    "full_report = df_result[['å–®ä½ä»£è™Ÿ', 'å–®ä½åç¨±', 'é …ç›®', 'å¹´ä»½', 'æœˆä»½', \n",
    "                        'è²»ç”¨', 'å¹³å‡è²»ç”¨', 'è¶…å‡ºå¹³å‡ç™¾åˆ†æ¯”', 'anomaly']]\n",
    "full_report.to_excel(\"è²»ç”¨ç•°å¸¸åµæ¸¬å ±å‘Š.xlsx\", index=False)\n",
    "\n",
    "print(\"âœ… å®Œæ•´è²»ç”¨ç•°å¸¸åµæ¸¬å ±å‘Šå·²åŒ¯å‡ºï¼ï¼ˆå«æ­£å¸¸èˆ‡ç•°å¸¸æ•¸æ“šï¼‰\")\n",
    "\n",
    "# æ¥è‘—åŸæœ¬çš„ç•°å¸¸æ˜ç´°å ±å‘Šï¼ˆåƒ…ç•°å¸¸ï¼‰\n",
    "anomalies = df_result[df_result['anomaly']]\n",
    "anomalies_report = anomalies[['å–®ä½ä»£è™Ÿ', 'å–®ä½åç¨±', 'é …ç›®', 'å¹´ä»½', 'æœˆä»½', 'è²»ç”¨', 'å¹³å‡è²»ç”¨', 'è¶…å‡ºå¹³å‡ç™¾åˆ†æ¯”', 'anomaly']]\n",
    "anomalies_report.to_excel(\"ç•°å¸¸æ•¸æ“šå ±å‘Š.xlsx\", index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
